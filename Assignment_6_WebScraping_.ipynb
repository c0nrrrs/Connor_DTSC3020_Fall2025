{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/c0nrrrs/Connor_DTSC3020_Fall2025/blob/main/Assignment_6_WebScraping_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_de5Eq4u-tR"
      },
      "source": [
        "# Assignment 6 (4 points) — Web Scraping\n",
        "\n",
        "In this assignment you will complete **two questions**. The **deadline is posted on Canvas**.\n"
      ],
      "id": "H_de5Eq4u-tR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PHwamZMu-tX"
      },
      "source": [
        "## Assignment Guide (Read Me First)\n",
        "\n",
        "- This notebook provides an **Install Required Libraries** cell and a **Common Imports & Polite Headers** cell. Run them first.\n",
        "- Each question includes a **skeleton**. The skeleton is **not** a solution; it is a lightweight scaffold you may reuse.\n",
        "- Under each skeleton you will find a **“Write your answer here”** code cell. Implement your scraping, cleaning, and saving logic there.\n",
        "- When your code is complete, run the **Runner** cell to print a Top‑15 preview and save the CSV.\n",
        "- Expected outputs:\n",
        "  - **Q1:** `data_q1.csv` + Top‑15 sorted by the specified numeric column.\n",
        "  - **Q2:** `data_q2.csv` + Top‑15 sorted by `points`.\n"
      ],
      "id": "4PHwamZMu-tX"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "I7DLq9nEu-tZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70656d45-c24e-48d5-dec0-241893a26558"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dependencies installed.\n"
          ]
        }
      ],
      "source": [
        "(1) #Install Required Libraries\n",
        "!pip -q install requests beautifulsoup4 lxml pandas\n",
        "print(\"Dependencies installed.\")\n"
      ],
      "id": "I7DLq9nEu-tZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ug_A9RuPu-tb"
      },
      "source": [
        "### 2) Common Imports & Polite Headers"
      ],
      "id": "ug_A9RuPu-tb"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Ov8pXh65u-tc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9852c22-68c5-410a-b9f1-bd67fe2494d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Common helpers loaded.\n"
          ]
        }
      ],
      "source": [
        "# Common Imports & Polite Headers\n",
        "import re, sys, pandas as pd, requests\n",
        "from bs4 import BeautifulSoup\n",
        "HEADERS = {\"User-Agent\": (\n",
        "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 \"\n",
        "    \"(KHTML, like Gecko) Chrome/122.0 Safari/537.36\")}\n",
        "def fetch_html(url: str, timeout: int = 20) -> str:\n",
        "    r = requests.get(url, headers=HEADERS, timeout=timeout)\n",
        "    r.raise_for_status()\n",
        "    return r.text\n",
        "def flatten_headers(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "        df.columns = [\" \".join([str(x) for x in tup if str(x)!=\"nan\"]).strip()\n",
        "                      for tup in df.columns.values]\n",
        "    else:\n",
        "        df.columns = [str(c).strip() for c in df.columns]\n",
        "    return df\n",
        "print(\"Common helpers loaded.\")\n"
      ],
      "id": "Ov8pXh65u-tc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km0GO7zzu-td"
      },
      "source": [
        "## Question 1 — IBAN Country Codes (table)\n",
        "**URL:** https://www.iban.com/country-codes  \n",
        "**Extract at least:** `Country`, `Alpha-2`, `Alpha-3`, `Numeric` (≥4 cols; you may add more)  \n",
        "**Clean:** trim spaces; `Alpha-2/Alpha-3` → **UPPERCASE**; `Numeric` → **int** (nullable OK)  \n",
        "**Output:** write **`data_q1.csv`** and **print a Top-15** sorted by `Numeric` (desc, no charts)  \n",
        "**Deliverables:** notebook + `data_q1.csv` + short `README.md` (URL, steps, 1 limitation)\n",
        "\n",
        "**Tip:** You can use `pandas.read_html(html)` to read tables and then pick one with ≥3 columns.\n"
      ],
      "id": "km0GO7zzu-td"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "q1_skeleton"
      },
      "outputs": [],
      "source": [
        "# --- Q1 Skeleton (fill the TODOs) ---\n",
        "def q1_read_table(html: str) -> pd.DataFrame:\n",
        "    \"\"\"Return the first table with >= 3 columns from the HTML.\n",
        "    TODO: implement with pd.read_html(html), pick a reasonable table, then flatten headers.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError(\"TODO: implement q1_read_table\")\n",
        "\n",
        "def q1_clean(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Clean columns: strip, UPPER Alpha-2/Alpha-3, cast Numeric to int (nullable), drop invalids.\n",
        "    TODO: implement cleaning steps.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError(\"TODO: implement q1_clean\")\n",
        "\n",
        "def q1_sort_top(df: pd.DataFrame, top: int = 15) -> pd.DataFrame:\n",
        "    \"\"\"Sort descending by Numeric and return Top-N.\n",
        "    TODO: implement.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError(\"TODO: implement q1_sort_top\")\n"
      ],
      "id": "q1_skeleton"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "q1_skeleton_answer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af8b796f-12e3-4454-9014-e056c4d34e50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-15 by Numeric Code:\n",
            "                                               Country Alpha-2 Code  \\\n",
            "247                                             ZAMBIA           ZM   \n",
            "246                                              YEMEN           YE   \n",
            "192                                              SAMOA           WS   \n",
            "244                                  WALLIS AND FUTUNA           WF   \n",
            "240                 VENEZUELA (BOLIVARIAN REPUBLIC OF)           VE   \n",
            "238                                         UZBEKISTAN           UZ   \n",
            "237                                            URUGUAY           UY   \n",
            "35                                        BURKINA FASO           BF   \n",
            "243                              VIRGIN ISLANDS (U.S.)           VI   \n",
            "236                     UNITED STATES OF AMERICA (THE)           US   \n",
            "219                       TANZANIA, UNITED REPUBLIC OF           TZ   \n",
            "108                                        ISLE OF MAN           IM   \n",
            "113                                             JERSEY           JE   \n",
            "92                                            GUERNSEY           GG   \n",
            "234  UNITED KINGDOM OF GREAT BRITAIN AND NORTHERN I...           GB   \n",
            "\n",
            "    Alpha-3 Code  Numeric Code  \n",
            "247          ZMB           894  \n",
            "246          YEM           887  \n",
            "192          WSM           882  \n",
            "244          WLF           876  \n",
            "240          VEN           862  \n",
            "238          UZB           860  \n",
            "237          URY           858  \n",
            "35           BFA           854  \n",
            "243          VIR           850  \n",
            "236          USA           840  \n",
            "219          TZA           834  \n",
            "108          IMN           833  \n",
            "113          JEY           832  \n",
            "92           GGY           831  \n",
            "234          GBR           826  \n"
          ]
        }
      ],
      "source": [
        "# Q1 — Write your answer here\n",
        "# --- Q1 Robust Solution ---\n",
        "\n",
        "from io import StringIO\n",
        "\n",
        "def q1_read_table(html: str) -> pd.DataFrame:\n",
        "    \"\"\"Return the first table with >= 3 columns from the HTML.\"\"\"\n",
        "    # Wrap HTML string for read_html (avoids the FutureWarning)\n",
        "    tables = pd.read_html(StringIO(html))\n",
        "    df = None\n",
        "    for t in tables:\n",
        "        if t.shape[1] >= 3:\n",
        "            df = t\n",
        "            break\n",
        "    df = flatten_headers(df)\n",
        "    return df\n",
        "\n",
        "\n",
        "def q1_clean(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Clean columns: strip, UPPER Alpha-2/Alpha-3, cast Numeric to int (nullable).\"\"\"\n",
        "    # Normalize headers\n",
        "    df.columns = [c.strip().title() for c in df.columns]\n",
        "\n",
        "    # Handle possible variants like \"Numeric\", \"Numeric Code\"\n",
        "    rename_map = {\n",
        "        \"Alpha-2 Code\": \"Alpha-2 Code\",\n",
        "        \"Alpha-3 Code\": \"Alpha-3 Code\",\n",
        "        \"Country\": \"Country\",\n",
        "        \"Numeric\": \"Numeric Code\",\n",
        "        \"Numeric Code\": \"Numeric Code\"\n",
        "    }\n",
        "    df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})\n",
        "\n",
        "    # Ensure required columns exist\n",
        "    keep = [c for c in [\"Country\", \"Alpha-2 Code\", \"Alpha-3 Code\", \"Numeric Code\"] if c in df.columns]\n",
        "    df = df[keep].copy()\n",
        "\n",
        "    # Clean up text\n",
        "    for c in [\"Country\", \"Alpha-2 Code\", \"Alpha-3 Code\"]:\n",
        "        if c in df.columns:\n",
        "            df[c] = df[c].astype(str).str.strip().str.upper()\n",
        "\n",
        "    # Convert numeric\n",
        "    if \"Numeric Code\" in df.columns:\n",
        "        df[\"Numeric Code\"] = pd.to_numeric(df[\"Numeric Code\"], errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "    return df.dropna(subset=[\"Country\"])\n",
        "\n",
        "\n",
        "def q1_sort_top(df: pd.DataFrame, top: int = 15) -> pd.DataFrame:\n",
        "    \"\"\"Sort descending by Numeric Code and return Top-N.\"\"\"\n",
        "    if \"Numeric Code\" in df.columns:\n",
        "        df = df.sort_values(by=\"Numeric Code\", ascending=False)\n",
        "    return df.head(top)\n",
        "\n",
        "\n",
        "# --- Run Q1 ---\n",
        "html = fetch_html(\"https://www.iban.com/country-codes\")\n",
        "df_q1 = q1_read_table(html)\n",
        "df_q1 = q1_clean(df_q1)\n",
        "top15_q1 = q1_sort_top(df_q1)\n",
        "\n",
        "print(\"Top-15 by Numeric Code:\")\n",
        "print(top15_q1)\n",
        "\n",
        "df_q1.to_csv(\"data_q1.csv\", index=False)\n",
        "\n"
      ],
      "id": "q1_skeleton_answer"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmefu--_u-tg"
      },
      "source": [
        "## Question 2 — Hacker News (front page)\n",
        "**URL:** https://news.ycombinator.com/  \n",
        "**Extract at least:** `rank`, `title`, `link`, `points`, `comments` (user optional)  \n",
        "**Clean:** cast `points`/`comments`/`rank` → **int** (non-digits → 0), fill missing text fields  \n",
        "**Output:** write **`data_q2.csv`** and **print a Top-15** sorted by `points` (desc, no charts)  \n",
        "**Tip:** Each story is a `.athing` row; details (points/comments/user) are in the next `<tr>` with `.subtext`.\n"
      ],
      "id": "rmefu--_u-tg"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "q2_skeleton"
      },
      "outputs": [],
      "source": [
        "# --- Q2 Skeleton (fill the TODOs) ---\n",
        "def q2_parse_items(html: str) -> pd.DataFrame:\n",
        "    \"\"\"Parse front page items into DataFrame columns:\n",
        "       rank, title, link, points, comments, user (optional).\n",
        "    TODO: implement with BeautifulSoup on '.athing' and its sibling '.subtext'.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError(\"TODO: implement q2_parse_items\")\n",
        "\n",
        "def q2_clean(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Clean numeric fields and fill missing values.\n",
        "    TODO: cast points/comments/rank to int (non-digits -> 0). Fill text fields.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError(\"TODO: implement q2_clean\")\n",
        "\n",
        "def q2_sort_top(df: pd.DataFrame, top: int = 15) -> pd.DataFrame:\n",
        "    \"\"\"Sort by points desc and return Top-N. TODO: implement.\"\"\"\n",
        "    raise NotImplementedError(\"TODO: implement q2_sort_top\")\n"
      ],
      "id": "q2_skeleton"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "q2_skeleton_answer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "890580e7-8b59-470f-a109-282f31aa6b66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-15 by Points:\n",
            "    rank                                              title  points  comments  \\\n",
            "29    30                   Solarpunk is happening in Africa    1097       533   \n",
            "28    29                          End of Japanese community     871       675   \n",
            "9     10                             Ratatui – App Showcase     673       189   \n",
            "7      8            FBI tries to unmask owner of archive.is     410       221   \n",
            "2      3             ICC ditches Microsoft 365 for openDesk     323        90   \n",
            "0      1  Kimi K2 Thinking, a SOTA open-source trillion-...     320       104   \n",
            "3      4  Open Source Implementation of Apple's Private ...     292        53   \n",
            "18    19  Cloudflare Tells U.S. Govt That Foreign Site B...     247       148   \n",
            "20    21  IKEA launches new smart home range with 21 Mat...     206       163   \n",
            "17    18  Australia has so much solar that it's offering...     204       153   \n",
            "26    27  I may have found a way to spot U.S. at-sea str...     203       262   \n",
            "14    15    Mathematical exploration and discovery at scale     193        82   \n",
            "25    26                  How I am deeply integrating Emacs     181       123   \n",
            "8      9                            Eating stinging nettles     125       123   \n",
            "6      7  I analyzed the lineups at the most popular nig...     116        60   \n",
            "\n",
            "              user  \n",
            "29         JoiDegn  \n",
            "28    phantomathkg  \n",
            "9         AbuAssar  \n",
            "7     Projectiboga  \n",
            "2         vincvinc  \n",
            "0        nekofneko  \n",
            "3   adam_gyroscope  \n",
            "18      iamnothere  \n",
            "20     lemoine0461  \n",
            "17          ohjeez  \n",
            "26         hentrep  \n",
            "14          nabla9  \n",
            "25         signa11  \n",
            "8              rzk  \n",
            "6            kalli  \n"
          ]
        }
      ],
      "source": [
        "# Q2 — Write your answer here\n",
        "# --- Q2 Solution ---\n",
        "\n",
        "def q2_parse_items(html: str) -> pd.DataFrame:\n",
        "    \"\"\"Parse front page items into DataFrame columns: rank, title, link, points, comments, user (optional).\"\"\"\n",
        "    soup = BeautifulSoup(html, \"lxml\")\n",
        "    items = soup.select(\".athing\")\n",
        "    data = []\n",
        "\n",
        "    for item in items:\n",
        "        rank_tag = item.select_one(\".rank\")\n",
        "        title_tag = item.select_one(\".titleline a\")\n",
        "        subtext = item.find_next_sibling(\"tr\").select_one(\".subtext\")\n",
        "\n",
        "        rank = rank_tag.text.strip().replace(\".\", \"\") if rank_tag else \"0\"\n",
        "        title = title_tag.text.strip() if title_tag else \"\"\n",
        "        link = title_tag.get(\"href\", \"\") if title_tag else \"\"\n",
        "\n",
        "        points_tag = subtext.select_one(\".score\") if subtext else None\n",
        "        user_tag = subtext.select_one(\".hnuser\") if subtext else None\n",
        "        comments_tag = subtext.find_all(\"a\")[-1] if subtext and subtext.find_all(\"a\") else None\n",
        "\n",
        "        points = points_tag.text.strip() if points_tag else \"0 points\"\n",
        "        user = user_tag.text.strip() if user_tag else \"\"\n",
        "        comments = comments_tag.text.strip() if comments_tag else \"0 comments\"\n",
        "\n",
        "        data.append({\n",
        "            \"rank\": rank,\n",
        "            \"title\": title,\n",
        "            \"link\": link,\n",
        "            \"points\": points,\n",
        "            \"comments\": comments,\n",
        "            \"user\": user\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "\n",
        "def q2_clean(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Clean numeric fields and fill missing values.\"\"\"\n",
        "    def extract_int(x):\n",
        "        m = re.search(r\"(\\d+)\", str(x))\n",
        "        return int(m.group(1)) if m else 0\n",
        "\n",
        "    for col in [\"rank\", \"points\", \"comments\"]:\n",
        "        df[col] = df[col].apply(extract_int)\n",
        "\n",
        "    # Fill missing text fields\n",
        "    for col in [\"title\", \"link\", \"user\"]:\n",
        "        df[col] = df[col].fillna(\"\").astype(str).str.strip()\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def q2_sort_top(df: pd.DataFrame, top: int = 15) -> pd.DataFrame:\n",
        "    \"\"\"Sort by points desc and return Top-N.\"\"\"\n",
        "    return df.sort_values(by=\"points\", ascending=False).head(top)\n",
        "\n",
        "\n",
        "# Q2 — Write your answer here\n",
        "html = fetch_html(\"https://news.ycombinator.com/\")\n",
        "df_q2 = q2_parse_items(html)\n",
        "df_q2 = q2_clean(df_q2)\n",
        "top15_q2 = q2_sort_top(df_q2)\n",
        "\n",
        "print(\"Top-15 by Points:\")\n",
        "print(top15_q2[[\"rank\", \"title\", \"points\", \"comments\", \"user\"]])\n",
        "\n",
        "df_q2.to_csv(\"data_q2.csv\", index=False)\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "q2_skeleton_answer"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}